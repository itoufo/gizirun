import OpenAI from 'openai'

function getOpenAI() {
  if (!process.env.OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY is not set')
  }
  return new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  })
}

export interface TokenUsage {
  inputTokens: number
  outputTokens: number
}

export interface TopicAnalysisResult {
  mainTopic: string | null
  currentTopic: string
  driftScore: number // 0-100 (50ä»¥ä¸Šã§ã‚¢ãƒ©ãƒ¼ãƒˆ)
  driftReason: string | null
  suggestedAction: string | null
  usage?: TokenUsage
}

export interface AnalyzeTopicParams {
  recentSegments: Array<{ speaker: string; text: string }>
  previousTopics: string[]
  mainTopic: string | null
  agendaItems: string[]
  isFirstAnalysis: boolean
  conversationSummary?: string | null // åœ§ç¸®ã•ã‚ŒãŸéå»ã®ä¼šè©±è¦ç´„
}

export async function analyzeTopics(params: AnalyzeTopicParams): Promise<TopicAnalysisResult> {
  const openai = getOpenAI()

  const segmentsText = params.recentSegments
    .map((s) => `${s.speaker}: ${s.text}`)
    .join('\n')

  const agendaText = params.agendaItems.length > 0
    ? params.agendaItems.map((item, i) => `${i + 1}. ${item}`).join('\n')
    : 'ãªã—'

  const previousTopicsText = params.previousTopics.length > 0
    ? params.previousTopics.slice(-5).join(' â†’ ')
    : 'ãªã—'

  const systemPrompt = `ã‚ãªãŸã¯ä¼šè­°ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ã‚’åˆ†æã—ã€ãƒˆãƒ”ãƒƒã‚¯ã®æµã‚Œã‚’è¿½è·¡ã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æã®ãƒã‚¤ãƒ³ãƒˆã€‘
- ãƒ¡ã‚¤ãƒ³ãƒˆãƒ”ãƒƒã‚¯: ä¼šè­°ã®ä¸»é¡Œï¼ˆ${params.isFirstAnalysis ? 'ä»Šå›æ¤œå‡ºã—ã¦ãã ã•ã„' : 'æ—¢ã«æ¤œå‡ºæ¸ˆã¿ãªã‚‰ç¶­æŒ'}ï¼‰
- ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯: ç›´è¿‘ã®ç™ºè¨€ã§è­°è«–ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯
- è„±ç·šåº¦(driftScore): 0-100ã®æ•°å€¤
  - 0-30: ãƒ¡ã‚¤ãƒ³ãƒˆãƒ”ãƒƒã‚¯ã«æ²¿ã£ãŸè­°è«–
  - 30-50: ã‚„ã‚„é–¢é€£æ€§ãŒè–„ã„ãŒè¨±å®¹ç¯„å›²
  - 50-70: æ˜ã‚‰ã‹ã«è„±ç·šã—ã¦ã„ã‚‹
  - 70-100: å®Œå…¨ã«ç„¡é–¢ä¿‚ãªè©±é¡Œ

ã€é‡è¦ã€‘
- æ—¥æœ¬ã®ä¼šè­°æ–‡åŒ–ã‚’è€ƒæ…®ã—ã€é›‘è«‡ã‚„é–¢ä¿‚æ§‹ç¯‰ã®ä¼šè©±ã¯éåº¦ã«å³ã—ãåˆ¤å®šã—ãªã„
- driftScoreãŒ50ä»¥ä¸Šã®å ´åˆã®ã¿ã€driftReasonã¨suggestedActionã‚’æä¾›
- suggestedActionã¯å…·ä½“çš„ã‹ã¤ä¸å¯§ãªææ¡ˆã«ã™ã‚‹

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{
  "mainTopic": "ä¼šè­°ã®ä¸»é¡Œï¼ˆåˆå›åˆ†ææ™‚ã®ã¿è¨­å®šã€ãã‚Œä»¥å¤–ã¯nullï¼‰",
  "currentTopic": "ç¾åœ¨è­°è«–ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯",
  "driftScore": 0-100ã®æ•°å€¤,
  "driftReason": "è„±ç·šç†ç”±ï¼ˆdriftScore >= 50ã®å ´åˆã®ã¿ï¼‰",
  "suggestedAction": "ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ã®ææ¡ˆï¼ˆdriftScore >= 50ã®å ´åˆã®ã¿ï¼‰"
}`

  const contextText = params.conversationSummary
    ? `ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã®è¦ç´„ã€‘:\n${params.conversationSummary}\n\n`
    : ''

  const userPrompt = `ã€ãƒ¡ã‚¤ãƒ³ãƒˆãƒ”ãƒƒã‚¯ã€‘: ${params.mainTopic || 'æœªæ¤œå‡º'}
ã€ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ã€‘:
${agendaText}
ã€ç›´å‰ã®ãƒˆãƒ”ãƒƒã‚¯ã®æµã‚Œã€‘: ${previousTopicsText}
${contextText}
ã€æœ€è¿‘ã®ç™ºè¨€ã€‘:
${segmentsText}

ã“ã®ä¼šè­°ã®ãƒˆãƒ”ãƒƒã‚¯åˆ†æã‚’JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚`

  const response = await openai.chat.completions.create({
    model: 'gpt-5.2',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ],
    response_format: {
      type: 'json_schema',
      json_schema: {
        name: 'topic_analysis',
        schema: {
          type: 'object',
          additionalProperties: false,
          properties: {
            mainTopic: { type: ['string', 'null'] },
            currentTopic: { type: 'string' },
            driftScore: { type: 'number' },
            driftReason: { type: ['string', 'null'] },
            suggestedAction: { type: ['string', 'null'] },
          },
          required: ['mainTopic', 'currentTopic', 'driftScore', 'driftReason', 'suggestedAction'],
        },
        strict: true,
      },
    },
    reasoning_effort: 'low',
    temperature: 0.3,
  })

  const content = response.choices[0].message.content
  if (!content) {
    throw new Error('No response from OpenAI')
  }

  const result = JSON.parse(content)

  return {
    mainTopic: params.isFirstAnalysis ? (result.mainTopic || null) : null,
    currentTopic: result.currentTopic || 'ä¸æ˜',
    driftScore: Math.min(100, Math.max(0, Number(result.driftScore) || 0)),
    driftReason: result.driftScore >= 50 ? (result.driftReason || null) : null,
    suggestedAction: result.driftScore >= 50 ? (result.suggestedAction || null) : null,
    usage: response.usage ? {
      inputTokens: response.usage.prompt_tokens,
      outputTokens: response.usage.completion_tokens,
    } : undefined,
  }
}

export function generateFacilitatorMessage(result: TopicAnalysisResult): string {
  if (result.driftScore < 50) {
    return ''
  }

  const severity = result.driftScore >= 70 ? 'å¤§ãã' : 'å°‘ã—'
  let message = `è©±é¡ŒãŒ${severity}ã‚ºãƒ¬ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚`

  if (result.driftReason) {
    message += `\n${result.driftReason}`
  }

  if (result.suggestedAction) {
    message += `\n\nğŸ’¡ ${result.suggestedAction}`
  }

  return message
}

// ä¼šè©±åœ§ç¸®ç”¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
export interface CompressConversationParams {
  segments: Array<{ speaker: string; text: string }>
  existingSummary: string | null
}

export interface CompressConversationResult {
  summary: string
  usage?: TokenUsage
}

/**
 * é•·æ™‚é–“ã®ä¼šè©±ã‚’åœ§ç¸®ã—ã¦è¦ç´„ã™ã‚‹
 * gpt-4o-miniã‚’ä½¿ç”¨ï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡ã®ãŸã‚ï¼‰
 */
export async function compressConversation(
  params: CompressConversationParams
): Promise<CompressConversationResult> {
  const openai = getOpenAI()

  const segmentsText = params.segments
    .map((s) => `${s.speaker}: ${s.text}`)
    .join('\n')

  const systemPrompt = `ã‚ãªãŸã¯ä¼šè­°ã®è¦ç´„è€…ã§ã™ã€‚
ä¼šè­°ã®ç™ºè¨€å†…å®¹ã‚’ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€è¦ç´„ã®ãƒã‚¤ãƒ³ãƒˆã€‘
- ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨è­°è«–ã®æµã‚Œã‚’ä¿æŒ
- é‡è¦ãªæ±ºå®šäº‹é …ã‚„åˆæ„ç‚¹ã‚’å«ã‚ã‚‹
- è©±è€…ã®ç«‹å ´ã‚„æ„è¦‹ã®é•ã„ã‚’åæ˜ 
- 200-300æ–‡å­—ç¨‹åº¦ã«åœ§ç¸®

${params.existingSummary ? `ã€æ—¢å­˜ã®è¦ç´„ã€‘\n${params.existingSummary}\n\næ–°ã—ã„ç™ºè¨€å†…å®¹ã‚’çµ±åˆã—ã¦æ›´æ–°ã—ã¦ãã ã•ã„ã€‚` : ''}`

  const userPrompt = `ã€ç™ºè¨€å†…å®¹ã€‘:
${segmentsText}

ä¸Šè¨˜ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚`

  const response = await openai.chat.completions.create({
    model: 'gpt-5-mini', // ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®ãŸã‚
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ],
    temperature: 0.3,
    max_tokens: 500,
  })

  const content = response.choices[0].message.content

  return {
    summary: content || '',
    usage: response.usage ? {
      inputTokens: response.usage.prompt_tokens,
      outputTokens: response.usage.completion_tokens,
    } : undefined,
  }
}
